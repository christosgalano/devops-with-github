# GitHub Models

> Develop and evaluate language model workflows directly in GitHub.

## Overview

GitHub Models is a workspace built into GitHub for working with large language models (LLMs). It supports prompt design, model comparison, evaluation, and integration—directly within your repository.

Main capabilities:
- Create prompts using a structured editor
- Run prompts against different LLMs using the same inputs
- Apply built-in evaluators to score responses
- Save configurations as `.prompt.yaml` files
- Connect via SDKs or the GitHub Models REST API

> GitHub Models is currently in public preview for organizations and repositories.

## Why use GitHub Models?

GitHub Models enables teams to build and evaluate AI-powered features without leaving their development workflow. It allows for:

- Designing and iterating on prompts in the GitHub UI
- Running side-by-side model comparisons
- Version-controlling prompts like code
- Sharing, reviewing, and reusing configurations
- Using structured evaluations to guide improvements

## Getting Started

![Overview](/assets/images/models/overview.webp)

### Models Catalog

To start, visit the [GitHub Models Marketplace](https://github.com/marketplace/models). Use the **Select a Model** dropdown to:

- View available models
- Check provider and SDK support
- Launch any model in the Playground

![Models Catalog](/assets/images/models/models-catalog.webp)
![Model Overview](/assets/images/models/model-overview.webp)

### Playground

The Playground allows for prompt development and testing.

You can:
- Enter system and user prompts
- Adjust temperature, token limits, and other parameters
- View responses from the model in real time
- Compare outputs from multiple models
- Export test configurations as code

#### Model Overview

Model details such as context window, release date, and supported features are visible on selection.

![GPT-4.1 Model Overview](/assets/images/models/model-gpt4.1.webp)

You can switch between:
- **Parameters**: modify model behavior
- **Chat / Code / Raw**: view response in different formats

#### Code View

The **Code** tab shows how to call the model using SDKs or direct API requests.

![Code View](/assets/images/models/code-view.webp)

### Prompt Editor

Use the **Prompt Editor** for single-turn prompts. This is useful when you're testing short inputs or working with clear system instructions.

![Prompt Editor](/assets/images/models/prompt-editor.webp)
![Prompt Editor Result 1](/assets/images/models/prompt-editor-result-1.webp)

If needed, use **Improve prompt** to refine it using suggestions generated by another model.

![Improve Prompt](/assets/images/models/improve-prompt.webp)
![Improved Prompt](/assets/images/models/improved-prompt.webp)

Run again to verify improvements.

![Prompt Editor Result 2](/assets/images/models/prompt-editor-result-2.webp)

### Model Comparison

The **Compare** function allows you to evaluate different models using the same prompt and input. This is useful for checking consistency, latency, or output quality.

![Model Comparison 1](/assets/images/models/model-comparison-1.webp)
![Model Comparison 2](/assets/images/models/model-comparison-2.webp)
![Model Comparison 3](/assets/images/models/model-comparison-3.webp)

### Use this Model

Once a model is selected, click **Use this model** to begin using it in a configured prompt file.

![Use this Model](/assets/images/models/use-this-model.webp)

## Repository Usage

GitHub Models can also be used inside your repository. Enable it in **Settings → Models**.

![Enable Models](/assets/images/models/enable-models.webp)

This adds a **Models** tab to the repo interface.

![Models Tab](/assets/images/models/repository-models.webp)

### Create a Prompt

Use the UI to create a `.prompt.yaml` file. This file defines:
- A `system` prompt
- A `user` prompt (can include variables like `{{input}}`)

![Repository Prompt 1](/assets/images/models/test-prompt-1.webp)
![Repository Prompt 2](/assets/images/models/test-prompt-2.webp)

### Store & Share

Prompts are stored as version-controlled YAML files. They can be reviewed and updated via pull requests like any other code artifact.

![Repository Prompt 3](/assets/images/models/test-prompt-3.webp)

### Run & View Output

You can execute prompts directly from the Models tab and inspect the output inline.

![Repository Prompt 4](/assets/images/models/test-prompt-4.webp)

## Evaluation

GitHub Models supports evaluation of model outputs using standard and custom metrics.

Available evaluators:
- **Similarity**: How close the result is to a reference output
- **Relevance**: Whether the output answers the input clearly and directly
- **Groundedness**: Whether the output stays true to the context
- **Custom**: User-defined checks for string presence or scoring logic

Evaluations can be applied to multiple prompt variants or model outputs. Results appear side by side for comparison.

![Evaluate](/assets/images/models/evaluate.webp)

## Resources

- [GitHub Models Documentation](https://docs.github.com/github-models)
- [GitHub Model Marketplace](https://github.com/marketplace/models)
